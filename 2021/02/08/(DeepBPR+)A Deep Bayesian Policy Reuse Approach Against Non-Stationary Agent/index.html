<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Opponent Modeling 2： A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents（Deep BPR+论文阅读笔记） | Xiguapi's Page</title><meta name="keywords" content="对手建模,Opponent Modeling,Deep BPR+"><meta name="author" content="Xiguapi"><meta name="copyright" content="Xiguapi"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="对手建模 Deep BPR+ NIPS2018">
<meta property="og:type" content="article">
<meta property="og:title" content="Opponent Modeling 2： A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents（Deep BPR+论文阅读笔记）">
<meta property="og:url" content="http://yuanyf.ml/2021/02/08/(DeepBPR+)A%20Deep%20Bayesian%20Policy%20Reuse%20Approach%20Against%20Non-Stationary%20Agent/index.html">
<meta property="og:site_name" content="Xiguapi&#39;s Page">
<meta property="og:description" content="对手建模 Deep BPR+ NIPS2018">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/02/27/PNrS8emZquV2sAJ.png">
<meta property="article:published_time" content="2021-02-08T07:51:11.000Z">
<meta property="article:modified_time" content="2021-02-08T07:51:14.000Z">
<meta property="article:author" content="Xiguapi">
<meta property="article:tag" content="对手建模">
<meta property="article:tag" content="Opponent Modeling">
<meta property="article:tag" content="Deep BPR+">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/27/PNrS8emZquV2sAJ.png"><link rel="shortcut icon" href="/img/icoon.jpg"><link rel="canonical" href="http://yuanyf.ml/2021/02/08/(DeepBPR+)A%20Deep%20Bayesian%20Policy%20Reuse%20Approach%20Against%20Non-Stationary%20Agent/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-02-08 15:51:14'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><meta name="generator" content="Hexo 5.2.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/a1.gif" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">34</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/algorithm/"><i class="fa-fw fas fa-robot"></i><span> 算法复现</span></a></div><div class="menus_item"><a class="site-page" href="/datashare/"><i class="fa-fw fas fa-table"></i><span> 资料分享</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://i.loli.net/2021/02/06/MNiconEbX84W3AL.png)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Xiguapi's Page</a></span><span id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/algorithm/"><i class="fa-fw fas fa-robot"></i><span> 算法复现</span></a></div><div class="menus_item"><a class="site-page" href="/datashare/"><i class="fa-fw fas fa-table"></i><span> 资料分享</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><h1 class="post-title">Opponent Modeling 2： A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents（Deep BPR+论文阅读笔记）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-02-08T07:51:11.000Z" title="发表于 2021-02-08 15:51:11">2021-02-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-02-08T07:51:14.000Z" title="更新于 2021-02-08 15:51:14">2021-02-08</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Opponent-Modeling/">Opponent Modeling</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="a-deep-bayesian-policy-reuse-approach-against-non-stationary-agentsnips-2018"><a class="markdownIt-Anchor" href="#a-deep-bayesian-policy-reuse-approach-against-non-stationary-agentsnips-2018"></a> A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents（NIPS 2018）</h1>
<h2 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> ABSTRACT</h2>
<p><strong>Why Opponent Modeling</strong>?</p>
<blockquote>
<p>coping with non-stationary agents that change behaviors<br />
from time to time</p>
</blockquote>
<p>为应对行为时刻发生变化的不稳定智能体，一个好的方法是快速检测对手的策略并调整自己的策略。</p>
<p><strong>和传统多智能体算法不同的是，对手建模关注对手的策略变化而传统多智能体算法仅关注对手行为</strong></p>
<p>因此本文提出了Deep BPR+算法（BPR -&gt; BPR+ -&gt; Deep BPR+）</p>
<h2 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> INTRODUCTION</h2>
<p>传统多智能体算法例如MADDPG等都没有显式的对agent策略进行分类，以至于很难学到更高的累积回报reward。</p>
<ul>
<li>显式识别对手不同策略，然后利用学到的策略去对抗不同的策略</li>
<li><strong>对手使用未知策略</strong>？ 通过策略神经网络快速学习</li>
</ul>
<p><strong>之前算法存在的局限性</strong></p>
<ul>
<li>BPR+的 internal belief model 的更新仅使用了reward信号，这样不足以去准确的检测到对方的策略。</li>
<li>如果遇到未知的对方策略，BPR+每次都从一个粗糙的策略里学习，不高效了。</li>
<li>BPR+存策略的方式类似一个Q-table，无法处理大量策略。</li>
</ul>
<p><strong>Deep BPR+的改进</strong></p>
<ul>
<li>使用opponent model对对手策略进行编码，使用reward + action的角度提升策略估计的准确性</li>
<li>对于未知的策略，使用了distailled policy network代替策略库，不用从头学起</li>
<li>存储方式同样使用这个蒸馏策略网络，可以处理大量策略</li>
</ul>
<h2 id="bpr-bprdeep-bpr"><a class="markdownIt-Anchor" href="#bpr-bprdeep-bpr"></a> BPR-&gt;BPR±&gt;Deep BPR+</h2>
<h3 id="bpr-贝叶斯策略重用"><a class="markdownIt-Anchor" href="#bpr-贝叶斯策略重用"></a> BPR 贝叶斯策略重用</h3>
<p><strong>在许多情况下，玩家需要使用一组策略，并在交互过程中在策略之间进行切换。BPR重点是在少量交互中重新记录玩家使用的策略,在agent面对未知任务时选择最优策略</strong>。</p>
<p>BPR的指标为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>U</mi><mi mathvariant="normal">∣</mi><mi>τ</mi><mo separator="true">,</mo><mi>π</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(U|\tau, \pi)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="mclose">)</span></span></span></span>，其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>U</mi></mrow><annotation encoding="application/x-tex">U</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span></span></span></span>为累积奖励，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>τ</mi></mrow><annotation encoding="application/x-tex">\tau</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span></span></span></span>为任务，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">π</span></span></span></span>为策略<br />
即<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>U</mi></mrow><annotation encoding="application/x-tex">U</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span></span></span></span>的概率分布，描述<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">π</span></span></span></span>如何作用于<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>τ</mi></mrow><annotation encoding="application/x-tex">\tau</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span></span></span></span>。</p>
<p>对之前已经解决的一组任务<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">T</mi></mrow><annotation encoding="application/x-tex">\Tau</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathrm">T</span></span></span></span></span>,有一个信心模型<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\beta(\tau)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="mclose">)</span></span></span></span>从累计奖励<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>U</mi></mrow><annotation encoding="application/x-tex">U</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span></span></span></span>的角度衡量当前任务task <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>τ</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">\tau^*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.688696em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span>和已知任务<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>τ</mi></mrow><annotation encoding="application/x-tex">\tau</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span></span></span></span>的匹配程度</p>
<p>同时<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>β</mi><mi>t</mi></msup><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\beta^t(\tau)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.043556em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="mclose">)</span></span></span></span>根据时间t使用贝叶斯公式进行更新：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>β</mi><mi>t</mi></msup><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>η</mi></mfrac><mi>P</mi><mrow><mo fence="true">(</mo><msup><mi>u</mi><mi>t</mi></msup><mo>∣</mo><mi>τ</mi><mo separator="true">,</mo><msup><mi>π</mi><mi>t</mi></msup><mo fence="true">)</mo></mrow><msup><mi>β</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\beta^{t}(\tau)=\frac{1}{\eta} P\left(u^{t} \mid \tau, \pi^{t}\right) \beta^{t-1}(\tau)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.093556em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.843556em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.20188em;vertical-align:-0.8804400000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">η</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.843556em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.843556em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.864108em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="mclose">)</span></span></span></span></span></p>
<p>其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>η</mi></mrow><annotation encoding="application/x-tex">\eta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span></span></span></span>标准化因子为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><munder><mo>∑</mo><mrow><msup><mi>τ</mi><mo mathvariant="normal">′</mo></msup><mo>∈</mo><mi mathvariant="script">T</mi></mrow></munder><mi>P</mi><mrow><mo fence="true">(</mo><msup><mi>u</mi><mi>t</mi></msup><mo>∣</mo><msup><mi>τ</mi><mo mathvariant="normal">′</mo></msup><mo separator="true">,</mo><msup><mi>π</mi><mi>t</mi></msup><mo fence="true">)</mo></mrow><msup><mi>β</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msup><mrow><mo fence="true">(</mo><msup><mi>τ</mi><mo mathvariant="normal">′</mo></msup><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\sum_{\tau^{\prime} \in \mathcal{T}} P\left(u^{t} \mid \tau^{\prime}, \pi^{t}\right) \beta^{t-1}\left(\tau^{\prime}\right)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.3717110000000003em;vertical-align:-1.321706em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8556639999999998em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.1132em;">τ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828285714285715em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.25417em;">T</span></span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.321706em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.843556em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.843556em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.864108em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span></span></p>
<p>整个模型原理即贝叶斯公式：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mrow><mo fence="true">(</mo><msub><mi>B</mi><mi>i</mi></msub><mo>∣</mo><mi>A</mi><mo fence="true">)</mo></mrow><mo>=</mo><mfrac><mrow><mi>P</mi><mrow><mo fence="true">(</mo><msub><mi>B</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><mi>P</mi><mrow><mo fence="true">(</mo><mi>A</mi><mo>∣</mo><msub><mi>B</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow></mrow><mrow><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>P</mi><mrow><mo fence="true">(</mo><msub><mi>B</mi><mi>j</mi></msub><mo fence="true">)</mo></mrow><mi>P</mi><mrow><mo fence="true">(</mo><mi>A</mi><mo>∣</mo><msub><mi>B</mi><mi>j</mi></msub><mo fence="true">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">P\left(B_{i} \mid A\right)=\frac{P\left(B_{i}\right) P\left(A \mid B_{i}\right)}{\sum_{j=1}^{n} P\left(B_{j}\right) P\left(A \mid B_{j}\right)}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathdefault">A</span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.55711em;vertical-align:-1.1301100000000002em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.305708em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.804292em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.43581800000000004em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1301100000000002em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>先对belief有一个概率分布，如果未知任务的分布和已知任务的匹配，则提高匹配度信心，根据对手策略的可能性在自身策略库中选择尽可能最大化累积奖励<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>U</mi></mrow><annotation encoding="application/x-tex">U</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span></span></span></span>的策略：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>π</mi><mo>∗</mo></msup><mo>=</mo><mi>arg</mi><mo>⁡</mo><munder><mo><mi>max</mi><mo>⁡</mo></mo><mrow><mi>π</mi><mo>∈</mo><mi mathvariant="normal">Π</mi></mrow></munder><msubsup><mo>∫</mo><mover accent="true"><mi>U</mi><mo>ˉ</mo></mover><mrow><mo>+</mo><mi mathvariant="normal">∞</mi></mrow></msubsup><munder><mo>∑</mo><mrow><mi>τ</mi><mo>∈</mo><mi mathvariant="script">T</mi></mrow></munder><mi>β</mi><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>U</mi><mo>∣</mo><mi>τ</mi><mo separator="true">,</mo><mi>π</mi><mo stretchy="false">)</mo><mi>d</mi><mi>U</mi></mrow><annotation encoding="application/x-tex">\pi^{*}=\arg \max _{\pi \in \Pi} \int_{\bar{U}}^{+\infty} \sum_{\tau \in \mathcal{T}} \beta(\tau) P(U \mid \tau, \pi) d U
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.738696em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.842937em;vertical-align:-1.321706em;"></span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.055669em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span><span class="mrel mtight">∈</span><span class="mord mtight">Π</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.771701em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5212310000000002em;"><span style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8201099999999999em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">U</span></span></span><span style="top:-2.9523300000000003em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mtight">ˉ</span></span></span></span></span></span></span></span></span></span><span style="top:-3.8129000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span><span class="mord mtight">∞</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9119499999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8556639999999998em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.1132em;">τ</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.25417em;">T</span></span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.321706em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="mclose">)</span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span></span></span></span></span></p>
<h3 id="bpr"><a class="markdownIt-Anchor" href="#bpr"></a> BPR+</h3>
<p>BPR+将BPR扩展到非平稳的多智能体对手，处理对方的不固定策略并学习新的策略</p>
<h3 id="policy-distillation"><a class="markdownIt-Anchor" href="#policy-distillation"></a> policy distillation</h3>
<p>让多个策略可以应用到同一个网络中</p>
<h3 id="deep-bpr"><a class="markdownIt-Anchor" href="#deep-bpr"></a> Deep BPR+</h3>
<p>与BPR+相比，解决了表格策略有限的问题——使用神经网络拟合<br />
如何检测对手的策略？基于奖励信号——基于奖励信号+基于观察的对手模型预测对手策略<br />
应对新策略从头开始训练成本高——蒸馏策略网络DPN，提炼一个启动策略</p>
<ul>
<li>策略重用阶段</li>
<li>新策略学习阶段</li>
</ul>
<p>在策略重用阶段，DBPR+通过Opponent Model修正的信心模型<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>β</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">\beta_{t-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.902771em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span></span></span></span>选择了一个合适的策略<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>π</mi><mi>t</mi></msup></mrow><annotation encoding="application/x-tex">\pi^t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7935559999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span></span></span>，然后得到一个累积收益<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>u</mi><mi>t</mi></msup></mrow><annotation encoding="application/x-tex">u^t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7935559999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span></span></span>。<br />
估计对手策略<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>τ</mi><mi>t</mi></msup></mrow><annotation encoding="application/x-tex">\tau^t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7935559999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span></span></span>，并用<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>u</mi><mi>t</mi></msup></mrow><annotation encoding="application/x-tex">u^t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7935559999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>τ</mi><mi>t</mi></msup></mrow><annotation encoding="application/x-tex">\tau^t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7935559999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span></span></span>更新 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>β</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\beta_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。<br />
check对手是否用的是没见过的策略，如果是则在下一个episode转换到学习阶段。</p>
<p>在学习阶段，由DPN获得初始策略。<br />
使用DQN训练对手策略<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>τ</mi><mi>t</mi></msup></mrow><annotation encoding="application/x-tex">\tau^t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7935559999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.1132em;">τ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span></span></span></span></span></span></span>，并放进已知对手策略库里，并且学习对应的策略在自己的策略库中。</p>
<h3 id="rectified-belief-model-修正信心模型"><a class="markdownIt-Anchor" href="#rectified-belief-model-修正信心模型"></a> Rectified Belief Model 修正信心模型</h3>
<p>核心即区分不同的对手策略并作出本身的策略反应</p>
<h3 id="distilled-policy-networkdpn-策略蒸馏网络"><a class="markdownIt-Anchor" href="#distilled-policy-networkdpn-策略蒸馏网络"></a> Distilled Policy Network(DPN) 策略蒸馏网络</h3>
<p><strong>解决遇到新策略时从头开始学习训练时间长的问题</strong></p>
<p><em>DBPR+和DRON有什么不同？</em></p>
<ul>
<li>DRON使用端到端的响应子网而DBPR+使用一对一响应策略</li>
<li>DRON不适合解决变化数量的对手，因为K是固定的，而DBPR+可以添加新的策略进入策略库</li>
<li>DRON需要更多的信息解决策略转换的问题</li>
</ul>
<h2 id="experiement"><a class="markdownIt-Anchor" href="#experiement"></a> EXPERIEMENT</h2>
<h3 id="环境描述"><a class="markdownIt-Anchor" href="#环境描述"></a> 环境描述</h3>
<p><img src="https://i.loli.net/2021/02/27/PNrS8emZquV2sAJ.png" alt="image.png" /></p>
<p>a环境：合作环境，两个agent A和O分别要到达各自的目标，到达目标reward +5，两个agent到达同一个目标reward -1，直到两agent到达目标则回合结束</p>
<p>b环境：合作环境，两个agent需要到达相同的目标，如果都到达相同的目标则正reward，否则则根据距离给予负reward</p>
<p>c环境：soccer环境，进球则reward +10 同时对手reward -10</p>
<p>环境中对手agent均采用不稳定策略，每隔几个回合就会切换策略</p>
<h3 id="学习未知策略"><a class="markdownIt-Anchor" href="#学习未知策略"></a> 学习未知策略</h3>
<p><img src="https://i.loli.net/2021/02/27/yoNlaz2SFhJeGtV.png" alt="image.png" /></p>
<p>BPR直接不行了，BPR+学习速度很慢，DBPR+效果不错</p>
<h3 id="疑问"><a class="markdownIt-Anchor" href="#疑问"></a> 疑问</h3>
<p>除了比较了学习未知策略和应对策略切换的情况，并没有展现具体检测到策略之后的效果和其他多智能体强化学习算法的优劣，可能BPR+已经比过了<br />
另外对策略切换的频率还是有一定限制的，不然会训练不出</p>
<h2 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> CONCLUSION</h2>
<ul>
<li>利用<strong>对手建模</strong>修正信念模型，从接受到的反馈（奖励等）和对手行为实现更精确的策略检测</li>
<li>对于未知策略，使用策略蒸馏实现更快的策略学习</li>
<li>主要算法：策略重用+新策略学习</li>
</ul>
<p>仍未解决的问题有：Agent的行为不断变化（每回合都变），较难学到一个好的策略</p>
<h2 id="为什么强调关注对手策略"><a class="markdownIt-Anchor" href="#为什么强调关注对手策略"></a> 为什么强调关注对手策略</h2>
<p><img src="https://i.loli.net/2021/02/27/kRcaOFerxCPj648.png" alt="image.png" /></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Xiguapi</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://yuanyf.ml/2021/02/08/(DeepBPR+)A%20Deep%20Bayesian%20Policy%20Reuse%20Approach%20Against%20Non-Stationary%20Agent/">http://yuanyf.ml/2021/02/08/(DeepBPR+)A%20Deep%20Bayesian%20Policy%20Reuse%20Approach%20Against%20Non-Stationary%20Agent/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://yuanyf.ml" target="_blank">Xiguapi's Page</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AF%B9%E6%89%8B%E5%BB%BA%E6%A8%A1/">对手建模</a><a class="post-meta__tags" href="/tags/Opponent-Modeling/">Opponent Modeling</a><a class="post-meta__tags" href="/tags/Deep-BPR/">Deep BPR+</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2021/02/27/PNrS8emZquV2sAJ.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/03/07/(DPIQN)A%20Deep%20Policy%20Inference%20Q-Network%20for%20Multi-Agent%20Systems/"><img class="prev-cover" src="https://i.loli.net/2021/03/10/doKT2WQphrujS5v.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Opponent Modeling 3： A Deep Policy Inference Q-Network for Multi-Agent Systems（论文阅读笔记）</div></div></a></div><div class="next-post pull-right"><a href="/2021/01/29/(DGN)GRAPH%20CONVOLUTIONAL%20REINFORCEMENT%20LEARNING/"><img class="next-cover" src="https://i.loli.net/2021/02/04/gHlpVbZ5n3AWeyQ.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">GNN 2: GRAPH CONVOLUTIONAL REINFORCEMENT LEARNING（论文阅读笔记）</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2021/03/07/(DPIQN)A Deep Policy Inference Q-Network for Multi-Agent Systems/" title="Opponent Modeling 3： A Deep Policy Inference Q-Network for Multi-Agent Systems（论文阅读笔记）"><img class="cover" src="https://i.loli.net/2021/03/10/doKT2WQphrujS5v.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-07</div><div class="title">Opponent Modeling 3： A Deep Policy Inference Q-Network for Multi-Agent Systems（论文阅读笔记）</div></div></a></div><div><a href="/2020/12/10/(DRON)Opponent Modeling in Deep Reinforcement Learning/" title="Opponent Modeling 1： Opponent Modeling in Deep Reinforcement Learning（论文阅读笔记）"><img class="cover" src="https://i.loli.net/2020/12/14/VhBtEAF8lOUoJwx.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-12-10</div><div class="title">Opponent Modeling 1： Opponent Modeling in Deep Reinforcement Learning（论文阅读笔记）</div></div></a></div><div><a href="/2021/03/12/(GASIL)predator-prey改进版实验环境/" title="GASIL cooperative predator-prey实验环境分析"><img class="cover" src="https://raw.githubusercontent.com/tjuHaoXiaotian/GASIL/master/files/img/predator-prey.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-12</div><div class="title">GASIL cooperative predator-prey实验环境分析</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="lv-container" data-id="city" data-uid="MTAyMC81MjMwOS8yODc4Nw"></div></div></div></div></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/a1.gif" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Xiguapi</div><div class="author-info__description">no fear of words, no fear of years.</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">34</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/pickxiguapi"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/pickxiguapi" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:yuanyf1999@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://qm.qq.com/cgi-bin/qm/qr?k=ioUJlpU-XAiqna8X8yWUgTxMVxykkhZ8&amp;noverify=0" target="_blank" title="QQ"><i class="fab fa-qq"></i></a></div></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">Be positive, be patient.</div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="card-content"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#a-deep-bayesian-policy-reuse-approach-against-non-stationary-agentsnips-2018"><span class="toc-number">1.</span> <span class="toc-text"> A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents（NIPS 2018）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#abstract"><span class="toc-number">1.1.</span> <span class="toc-text"> ABSTRACT</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#introduction"><span class="toc-number">1.2.</span> <span class="toc-text"> INTRODUCTION</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#bpr-bprdeep-bpr"><span class="toc-number">1.3.</span> <span class="toc-text"> BPR-&gt;BPR±&gt;Deep BPR+</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#bpr-%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AD%96%E7%95%A5%E9%87%8D%E7%94%A8"><span class="toc-number">1.3.1.</span> <span class="toc-text"> BPR 贝叶斯策略重用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#bpr"><span class="toc-number">1.3.2.</span> <span class="toc-text"> BPR+</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#policy-distillation"><span class="toc-number">1.3.3.</span> <span class="toc-text"> policy distillation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#deep-bpr"><span class="toc-number">1.3.4.</span> <span class="toc-text"> Deep BPR+</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rectified-belief-model-%E4%BF%AE%E6%AD%A3%E4%BF%A1%E5%BF%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.3.5.</span> <span class="toc-text"> Rectified Belief Model 修正信心模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#distilled-policy-networkdpn-%E7%AD%96%E7%95%A5%E8%92%B8%E9%A6%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">1.3.6.</span> <span class="toc-text"> Distilled Policy Network(DPN) 策略蒸馏网络</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#experiement"><span class="toc-number">1.4.</span> <span class="toc-text"> EXPERIEMENT</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E6%8F%8F%E8%BF%B0"><span class="toc-number">1.4.1.</span> <span class="toc-text"> 环境描述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E6%9C%AA%E7%9F%A5%E7%AD%96%E7%95%A5"><span class="toc-number">1.4.2.</span> <span class="toc-text"> 学习未知策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%96%91%E9%97%AE"><span class="toc-number">1.4.3.</span> <span class="toc-text"> 疑问</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#conclusion"><span class="toc-number">1.5.</span> <span class="toc-text"> CONCLUSION</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BC%BA%E8%B0%83%E5%85%B3%E6%B3%A8%E5%AF%B9%E6%89%8B%E7%AD%96%E7%95%A5"><span class="toc-number">1.6.</span> <span class="toc-text"> 为什么强调关注对手策略</span></a></li></ol></li></ol></div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/03/18/(GAT)GRAPH%20ATTENTION%20NETWORKS/" title="GNN 4: GRAPH ATTENTION NETWORKS（GAT论文阅读笔记及相关理解）"><img src="https://i.loli.net/2021/03/19/2BlMqDRP98wdigk.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="GNN 4: GRAPH ATTENTION NETWORKS（GAT论文阅读笔记及相关理解）"/></a><div class="content"><a class="title" href="/2021/03/18/(GAT)GRAPH%20ATTENTION%20NETWORKS/" title="GNN 4: GRAPH ATTENTION NETWORKS（GAT论文阅读笔记及相关理解）">GNN 4: GRAPH ATTENTION NETWORKS（GAT论文阅读笔记及相关理解）</a><time datetime="2021-03-18T09:20:17.000Z" title="发表于 2021-03-18 17:20:17">2021-03-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/03/12/(GASIL)predator-prey%E6%94%B9%E8%BF%9B%E7%89%88%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83/" title="GASIL cooperative predator-prey实验环境分析"><img src="https://raw.githubusercontent.com/tjuHaoXiaotian/GASIL/master/files/img/predator-prey.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="GASIL cooperative predator-prey实验环境分析"/></a><div class="content"><a class="title" href="/2021/03/12/(GASIL)predator-prey%E6%94%B9%E8%BF%9B%E7%89%88%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83/" title="GASIL cooperative predator-prey实验环境分析">GASIL cooperative predator-prey实验环境分析</a><time datetime="2021-03-12T02:45:54.000Z" title="发表于 2021-03-12 10:45:54">2021-03-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/03/07/(DPIQN)A%20Deep%20Policy%20Inference%20Q-Network%20for%20Multi-Agent%20Systems/" title="Opponent Modeling 3： A Deep Policy Inference Q-Network for Multi-Agent Systems（论文阅读笔记）"><img src="https://i.loli.net/2021/03/10/doKT2WQphrujS5v.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Opponent Modeling 3： A Deep Policy Inference Q-Network for Multi-Agent Systems（论文阅读笔记）"/></a><div class="content"><a class="title" href="/2021/03/07/(DPIQN)A%20Deep%20Policy%20Inference%20Q-Network%20for%20Multi-Agent%20Systems/" title="Opponent Modeling 3： A Deep Policy Inference Q-Network for Multi-Agent Systems（论文阅读笔记）">Opponent Modeling 3： A Deep Policy Inference Q-Network for Multi-Agent Systems（论文阅读笔记）</a><time datetime="2021-03-07T13:12:02.000Z" title="发表于 2021-03-07 21:12:02">2021-03-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/02/08/(DeepBPR+)A%20Deep%20Bayesian%20Policy%20Reuse%20Approach%20Against%20Non-Stationary%20Agent/" title="Opponent Modeling 2： A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents（Deep BPR+论文阅读笔记）"><img src="https://i.loli.net/2021/02/27/PNrS8emZquV2sAJ.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Opponent Modeling 2： A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents（Deep BPR+论文阅读笔记）"/></a><div class="content"><a class="title" href="/2021/02/08/(DeepBPR+)A%20Deep%20Bayesian%20Policy%20Reuse%20Approach%20Against%20Non-Stationary%20Agent/" title="Opponent Modeling 2： A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents（Deep BPR+论文阅读笔记）">Opponent Modeling 2： A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents（Deep BPR+论文阅读笔记）</a><time datetime="2021-02-08T07:51:11.000Z" title="发表于 2021-02-08 15:51:11">2021-02-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/01/29/(DGN)GRAPH%20CONVOLUTIONAL%20REINFORCEMENT%20LEARNING/" title="GNN 2: GRAPH CONVOLUTIONAL REINFORCEMENT LEARNING（论文阅读笔记）"><img src="https://i.loli.net/2021/02/04/gHlpVbZ5n3AWeyQ.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="GNN 2: GRAPH CONVOLUTIONAL REINFORCEMENT LEARNING（论文阅读笔记）"/></a><div class="content"><a class="title" href="/2021/01/29/(DGN)GRAPH%20CONVOLUTIONAL%20REINFORCEMENT%20LEARNING/" title="GNN 2: GRAPH CONVOLUTIONAL REINFORCEMENT LEARNING（论文阅读笔记）">GNN 2: GRAPH CONVOLUTIONAL REINFORCEMENT LEARNING（论文阅读笔记）</a><time datetime="2021-01-29T01:39:25.000Z" title="发表于 2021-01-29 09:39:25">2021-01-29</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Xiguapi</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> {preloader.endLoading()})</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>$(function () {
  $('span.katex-display').wrap('<div class="katex-wrap"></div>')
})</script><script>function loadLivere () {
  if (typeof LivereTower === 'object') {
    window.LivereTower.init()
  }
  else {
    (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
    })(document, 'script');
  }
}

if ('Livere' === 'Livere' || !false) {
  if (false) btf.loadComment(document.getElementById('lv-container'), loadLivere)
  else loadLivere()
}
else {
  function loadOtherComment () {
    loadLivere()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script></div></body></html>