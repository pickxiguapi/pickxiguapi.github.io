<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>动态规划求解小型方格世界最优策略 | Xiguapi's Page</title><meta name="keywords" content="MDP,dynamic programming,Bellman equation"><meta name="author" content="Xiguapi"><meta name="copyright" content="Xiguapi"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="We use dynamic programming method for strategy evalution, strategy iteration and value iteration based on 4*4 square world.">
<meta property="og:type" content="article">
<meta property="og:title" content="动态规划求解小型方格世界最优策略">
<meta property="og:url" content="http://yuanyf.ml/2020/11/10/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92MDP/index.html">
<meta property="og:site_name" content="Xiguapi&#39;s Page">
<meta property="og:description" content="We use dynamic programming method for strategy evalution, strategy iteration and value iteration based on 4*4 square world.">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://images.pexels.com/photos/261719/pexels-photo-261719.jpeg?cs=srgb&dl=pexels-pixabay-261719.jpg&fm=jpg">
<meta property="article:published_time" content="2020-11-10T06:28:54.000Z">
<meta property="article:modified_time" content="2020-11-12T06:28:58.000Z">
<meta property="article:author" content="Xiguapi">
<meta property="article:tag" content="MDP">
<meta property="article:tag" content="dynamic programming">
<meta property="article:tag" content="Bellman equation">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://images.pexels.com/photos/261719/pexels-photo-261719.jpeg?cs=srgb&dl=pexels-pixabay-261719.jpg&fm=jpg"><link rel="shortcut icon" href="/img/icoon.jpg"><link rel="canonical" href="http://yuanyf.ml/2020/11/10/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92MDP/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2020-11-12 14:28:58'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><meta name="generator" content="Hexo 5.2.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/a1.gif" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">34</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/algorithm/"><i class="fa-fw fas fa-robot"></i><span> 算法复现</span></a></div><div class="menus_item"><a class="site-page" href="/datashare/"><i class="fa-fw fas fa-table"></i><span> 资料分享</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://images.pexels.com/photos/5534634/pexels-photo-5534634.jpeg?cs=srgb&amp;dl=pexels-jo-kassis-5534634.jpg&amp;fm=jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Xiguapi's Page</a></span><span id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/algorithm/"><i class="fa-fw fas fa-robot"></i><span> 算法复现</span></a></div><div class="menus_item"><a class="site-page" href="/datashare/"><i class="fa-fw fas fa-table"></i><span> 资料分享</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><h1 class="post-title">动态规划求解小型方格世界最优策略</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-11-10T06:28:54.000Z" title="发表于 2020-11-10 14:28:54">2020-11-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-11-12T06:28:58.000Z" title="更新于 2020-11-12 14:28:58">2020-11-12</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Reinforcement-Learning-Tutorial/">Reinforcement Learning Tutorial</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="动态规划求解小型方格世界最优策略"><a class="markdownIt-Anchor" href="#动态规划求解小型方格世界最优策略"></a> 动态规划求解小型方格世界最优策略</h1>
<h2 id="动态规划思想"><a class="markdownIt-Anchor" href="#动态规划思想"></a> 动态规划思想</h2>
<p>动态规划算法把求解复杂问题分解为求解子问题，通过求解子问题进而得到整个问题的解。在解决子问题的时候，其结果通常需要存储起来被用来解决后续复杂问题。当问题具有下列两个性质时，通常可以考虑使用动态规划来求解:第一个性质是一个复杂问题的最优解由数个小问题的最优解构成，可以通过寻找子问题的最优解来得到复杂问题的最优解;第二个性质是子问题在复杂问题内重复出现，使得子问题的解可以被存储起来重复利用。<strong>马尔科夫决策过程具有上述两个属性:贝尔曼方程把问题递归为求解子问题，价值函数相当于存储了一些子问题的解，可以复用。因此可以使用动态规划来求解马尔科夫决策过程。</strong></p>
<p>动态规划的两种核心内容是<strong>预测</strong>和<strong>控制</strong>，预测即给定策略π和MDP模型，求解基于该策略的价值函数V，控制即已知MDP模型，求解最优价值函数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>v</mi><mo>∗</mo></msub></mrow><annotation encoding="application/x-tex">v_*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.175696em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和最优策略<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>π</mi><mo>∗</mo></msub></mrow><annotation encoding="application/x-tex">π_*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.175696em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。</p>
<h2 id="44小型方格世界mdp建模"><a class="markdownIt-Anchor" href="#44小型方格世界mdp建模"></a> 4*4小型方格世界MDP建模</h2>
<p>我们对4*4小型方格世界进行MDP建模来验证动态规划方法，定义MDP为<code>S, A, R, P, gamma</code>五元组：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">S = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">16</span>)]  <span class="comment"># 状态空间</span></span><br><span class="line">A = [<span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;w&#x27;</span>]  <span class="comment"># 动作空间</span></span><br><span class="line"><span class="comment"># P, R 动态生成</span></span><br><span class="line"></span><br><span class="line">actions = &#123;<span class="string">&#x27;n&#x27;</span>: <span class="number">-4</span>, <span class="string">&#x27;e&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;s&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;w&#x27;</span>: <span class="number">-1</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dynamics</span>(<span class="params">s, a</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            s state 0-15</span></span><br><span class="line"><span class="string">            a action [&#x27;n&#x27;, &#x27;e&#x27;, &#x27;s&#x27;, &#x27;w&#x27;]</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            tuple(s_prime, reward, is_end)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        0/15 terminal</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    s_prime = s</span><br><span class="line">    <span class="keyword">if</span> (s % <span class="number">4</span> == <span class="number">0</span> <span class="keyword">and</span> a == <span class="string">&quot;w&quot;</span>) <span class="keyword">or</span> (s &lt; <span class="number">4</span> <span class="keyword">and</span> a == <span class="string">&quot;n&quot;</span>) <span class="keyword">or</span> ((s + <span class="number">1</span>) % <span class="number">4</span> == <span class="number">0</span> <span class="keyword">and</span> a == <span class="string">&quot;e&quot;</span>) <span class="keyword">or</span> (s &gt; <span class="number">11</span> <span class="keyword">and</span> a == <span class="string">&quot;s&quot;</span>) <span class="keyword">or</span> s <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">15</span>]:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ds = actions[a]</span><br><span class="line">        s_prime = s + ds</span><br><span class="line">        reward = <span class="number">0</span> <span class="keyword">if</span> s <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">15</span>] <span class="keyword">else</span> <span class="number">-1</span></span><br><span class="line">        is_end = <span class="literal">True</span> <span class="keyword">if</span> s <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">15</span>] <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> s_prime, reward, is_end</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">P</span>(<span class="params">s, a, s1</span>):</span></span><br><span class="line">    <span class="comment"># 状态转移函数 状态s执行a动作转移到s1的概率 此处只有1或者0</span></span><br><span class="line">    s_prime, _, _ = dynamics(s, a)</span><br><span class="line">    <span class="keyword">return</span> s_prime == s1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">R</span>(<span class="params">s, a</span>):</span></span><br><span class="line">    _, r, _ = dynamics(s, a)</span><br><span class="line">    <span class="keyword">return</span> r</span><br><span class="line"></span><br><span class="line">gamma = <span class="number">1</span></span><br><span class="line"><span class="comment"># MDP 5 tuple</span></span><br><span class="line">MDP = S, A, R, P, gamma</span><br></pre></td></tr></table></figure>
<p>在小型方格世界中的个体有两种简单易行的策略，分别是<strong>完全随机策略</strong>和<strong>完全贪婪策略</strong>，完全随机策略即完全随机动作，完全贪婪策略即个体在任何一个状态时，将比较所有后续可能的状态的价值，并保证从中选择一个最大价值的状态以及能到达这一状态的行为。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Part 2</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 完全随机策略</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">uniform_pi</span>(<span class="params">MDP=MDP, V=<span class="literal">None</span>, s=<span class="literal">None</span>, a=<span class="literal">None</span></span>):</span></span><br><span class="line">    _, A, _, _, _ = MDP</span><br><span class="line">    n = <span class="built_in">len</span>(A)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span> <span class="keyword">if</span> n == <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span> / n</span><br><span class="line"></span><br><span class="line"><span class="comment"># 完全贪婪策略</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greedy_pi</span>(<span class="params">MDP, V, s, a</span>):</span></span><br><span class="line">    S, A, P, R, gamma = MDP</span><br><span class="line">    max_v, a_max_v = -<span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>), []</span><br><span class="line">    <span class="keyword">for</span> a_opt <span class="keyword">in</span> A:</span><br><span class="line">        <span class="comment"># 后续状态的最大价值以及到达该状态的行为</span></span><br><span class="line">        s_prime, reward, _ = dynamics(s, a_opt)</span><br><span class="line">        v_s_prime = get_value(V, s_prime)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> v_s_prime &gt; max_v:</span><br><span class="line">            max_v = v_s_prime</span><br><span class="line">            a_max_v = [a_opt]</span><br><span class="line">        <span class="keyword">elif</span> v_s_prime == max_v:</span><br><span class="line">            a_max_v.append(a_opt)</span><br><span class="line"></span><br><span class="line">    n = <span class="built_in">len</span>(a_max_v)</span><br><span class="line">    <span class="keyword">if</span> n == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span> / n <span class="keyword">if</span> a <span class="keyword">in</span> a_max_v <span class="keyword">else</span> <span class="number">0.0</span></span><br></pre></td></tr></table></figure>
<p>余下还有一些辅助函数，主要是获取状态及奖励等</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_reward</span>(<span class="params">R, s, a</span>):</span></span><br><span class="line">    <span class="comment"># 获取奖励值</span></span><br><span class="line">    <span class="keyword">return</span> R(s, a)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">display_V</span>(<span class="params">V</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">16</span>):</span><br><span class="line">        print(<span class="string">&#x27;&#123;0:&gt;6.1f&#125;&#x27;</span>.<span class="built_in">format</span>(V[i]), end=<span class="string">&quot; &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> (i + <span class="number">1</span>) % <span class="number">4</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">&quot;&quot;</span>)</span><br><span class="line">    print()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_value</span>(<span class="params">V, s, v</span>):</span></span><br><span class="line">    <span class="comment"># set value dict</span></span><br><span class="line">    V[s] = v</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_value</span>(<span class="params">V, s</span>):</span></span><br><span class="line">    <span class="comment"># get value</span></span><br><span class="line">    <span class="keyword">return</span> V[s]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_Pi</span>(<span class="params">Pi, s, a, MDP=<span class="literal">None</span>, V=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="keyword">return</span> Pi(MDP, V, s, a)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_prob</span>(<span class="params">P, s, a, s1</span>):</span></span><br><span class="line">    <span class="comment"># 获取状态转移概率</span></span><br><span class="line">    <span class="keyword">return</span> P(s, a, s1)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="策略评估policy-evalution"><a class="markdownIt-Anchor" href="#策略评估policy-evalution"></a> 策略评估(Policy evalution)</h2>
<p>给定策略下状态价值函数的动态过程：从任意一个状态价值函数开始，依据给定的策略，结合贝尔曼期望方程计算状态价值函数。贝尔曼方程使用第k轮迭代的后续状态s’来计算第k+1轮迭代的当前状态s的价值。（非常绕，但是代码比较清晰）</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>v</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mrow><mi>a</mi><mo>∈</mo><mi>A</mi></mrow></munder><mi>π</mi><mo stretchy="false">(</mo><mi>a</mi><mo>∣</mo><mi>s</mi><mo stretchy="false">)</mo><mrow><mo fence="true">(</mo><msubsup><mi>R</mi><mi>s</mi><mi>a</mi></msubsup><mo>+</mo><mi>γ</mi><munder><mo>∑</mo><mrow><msup><mi>s</mi><mo mathvariant="normal">′</mo></msup><mo>∈</mo><mi>S</mi></mrow></munder><msubsup><mi>P</mi><mrow><mi>s</mi><msup><mi>s</mi><mo mathvariant="normal">′</mo></msup></mrow><mi>a</mi></msubsup><msub><mi>v</mi><mi>k</mi></msub><mrow><mo fence="true">(</mo><msup><mi>s</mi><mo mathvariant="normal">′</mo></msup><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">v_{k+1}(s)=\sum_{a \in A} \pi(a \mid s)\left(R_{s}^{a}+\gamma \sum_{s^{\prime} \in S} P_{s s^{\prime}}^{a} v_{k}\left(s^{\prime}\right)\right)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.3717110000000003em;vertical-align:-1.321706em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8556639999999998em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mrel mtight">∈</span><span class="mord mathdefault mtight">A</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.321706em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.071706em;vertical-align:-1.321706em;"></span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">(</span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7143919999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8556639999999998em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828285714285715em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.321706em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7143919999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828285714285715em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size4">)</span></span></span></span></span></span></span></p>
<p>即迭代当前状态s向上/下/左/右移动行为的概率 × [当前状态s向上/下/左/右移动行为的奖励 + γ (当前状态s向上/下/左/右移动行为进行下一状态s’的状态转化概率) × 上一轮迭代时状态s’的价值 ]</p>
<p><em>注意：在该环境下，存在特殊情况，例如状态1采取向上的动作N，此时不能超出地图范围，s’为保持原位不动，但是动作是可执行的</em></p>
<p>以迭代轮次<code>k=1</code>和迭代轮次<code>k=2</code>为例，<code>k=1</code>时<code>V[0]=0</code>，<code>V[2]=-1.0</code>，<code>V[5]=-1.0</code>，则计算<code>k=2</code>轮次的<code>V[1]</code>则有<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>V</mi><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo><mo>=</mo><mn>0.25</mn><mo>∗</mo><mo stretchy="false">(</mo><mo>−</mo><mn>1</mn><mo>+</mo><mn>1</mn><mo>∗</mo><mn>0</mn><mo stretchy="false">)</mo><mo>+</mo><mn>0.25</mn><mo>∗</mo><mo stretchy="false">(</mo><mo>−</mo><mn>1</mn><mo>+</mo><mn>1</mn><mo>∗</mo><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo>+</mo><mn>0.25</mn><mo>∗</mo><mo stretchy="false">(</mo><mo>−</mo><mn>1</mn><mo>+</mo><mn>1</mn><mo>∗</mo><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo>+</mo><mn>0.25</mn><mo>∗</mo><mo stretchy="false">(</mo><mo>−</mo><mn>1</mn><mo>+</mo><mn>1</mn><mo>∗</mo><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mn>1.75</mn></mrow><annotation encoding="application/x-tex">V[1] = 0.25*(-1 + 1 * 0) + 0.25*(-1 + 1 * -1) + 0.25*(-1 + 1 * -1) + 0.25*(-1 + 1 * -1) = -1.75</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">2</span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">0</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">2</span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">2</span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">2</span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">−</span><span class="mord">1</span><span class="mord">.</span><span class="mord">7</span><span class="mord">5</span></span></span></span></p>
<p>核心代码<code>compute_v</code> <code>compute_q</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_v</span>(<span class="params">MDP, V, Pi, s</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        给定MDP，依据某一策略Pi和当前状态价值函数V，计算某状态s的价值</span></span><br><span class="line"><span class="string">        get_Pi: 基于当前策略π，状态为s的情况下选择动作a的概率</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    S, A, R, P, gamma = MDP</span><br><span class="line">    v_s = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> A:</span><br><span class="line">        v_s += get_Pi(Pi, s, a, MDP, V) * compute_q(MDP, V, s, a)</span><br><span class="line">    <span class="keyword">return</span> v_s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_q</span>(<span class="params">MDP, V, s, a</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        根据给定的MDP， 价值函数V， 计算状态行为对Q(s, a)</span></span><br><span class="line"><span class="string">        get_prob: 获取状态转移概率 在该环境中，状态s使用动作a到达状态s&#x27;的概率为1或者0</span></span><br><span class="line"><span class="string">        get_value: 获取价值字典，即获取V[s]</span></span><br><span class="line"><span class="string">        get_reward: 获取在状态s使用动作a得到的奖励值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        对应贝尔曼方程中的括号中部分</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    S, A, R, P, gamma = MDP</span><br><span class="line">    q_sa = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> s_prime <span class="keyword">in</span> S:</span><br><span class="line">        q_sa += get_prob(P, s, a, s_prime) * get_value(V, s_prime)</span><br><span class="line">    q_sa = get_reward(R, s, a) + gamma * q_sa</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> q_sa</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_V</span>(<span class="params">MDP, V, Pi</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        根据给定的MDP 和 Pi，更新当前的V</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    S, _, _, _, _ = MDP</span><br><span class="line">    V_prime = V.copy()</span><br><span class="line">    v_list = <span class="built_in">list</span>()</span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> S:</span><br><span class="line">        v = compute_v(MDP, V_prime, Pi, s)</span><br><span class="line">        v_list.append(v)</span><br><span class="line">    k = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> S:</span><br><span class="line">        set_value(V, s, v_list[k])</span><br><span class="line">        k += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> V</span><br></pre></td></tr></table></figure>
<p>根据如上计算方式，我们先来分别评估完全随机策略和贪婪策略下16个状态的最终价值</p>
<p><strong>完全随机策略</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">policy_evaluate</span>(<span class="params">MDP, V, pi, n</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        param:</span></span><br><span class="line"><span class="string">            MDP 建立的MDP模型</span></span><br><span class="line"><span class="string">            V 初始状态值函数</span></span><br><span class="line"><span class="string">            pi 使用的策略</span></span><br><span class="line"><span class="string">            n 迭代次数</span></span><br><span class="line"><span class="string">        return：</span></span><br><span class="line"><span class="string">            V_eva 在n次迭代之后按照给定策略MDP的V值分布</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        V = update_V(MDP, V, pi)</span><br><span class="line">    <span class="keyword">return</span> V</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">V = [<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">16</span>)]  <span class="comment"># 初始化价值</span></span><br><span class="line">V_eva = policy_evaluate(MDP, V, uniform_pi, <span class="number">100</span>)  <span class="comment"># 设置迭代轮次为100轮，即达到无穷大收敛状态</span></span><br><span class="line">display_V(V_eva)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; 策略评估 完全随机策略</span></span><br><span class="line"><span class="string"># 迭代1轮的结果</span></span><br><span class="line"><span class="string">   0.0   -1.0   -1.0   -1.0 </span></span><br><span class="line"><span class="string">  -1.0   -1.0   -1.0   -1.0 </span></span><br><span class="line"><span class="string">  -1.0   -1.0   -1.0   -1.0 </span></span><br><span class="line"><span class="string">  -1.0   -1.0   -1.0    0.0 </span></span><br><span class="line"><span class="string"># 迭代2轮的结果</span></span><br><span class="line"><span class="string">   0.0   -1.8   -2.0   -2.0 </span></span><br><span class="line"><span class="string">  -1.8   -2.0   -2.0   -2.0 </span></span><br><span class="line"><span class="string">  -2.0   -2.0   -2.0   -1.8 </span></span><br><span class="line"><span class="string">  -2.0   -2.0   -1.8    0.0 </span></span><br><span class="line"><span class="string"># 迭代3轮的结果</span></span><br><span class="line"><span class="string">   0.0   -2.4   -2.9   -3.0 </span></span><br><span class="line"><span class="string">  -2.4   -2.9   -3.0   -2.9 </span></span><br><span class="line"><span class="string">  -2.9   -3.0   -2.9   -2.4 </span></span><br><span class="line"><span class="string">  -3.0   -2.9   -2.4    0.0 </span></span><br><span class="line"><span class="string"># 迭代100轮的结果</span></span><br><span class="line"><span class="string">  0.0  -13.9  -19.9  -21.9 </span></span><br><span class="line"><span class="string"> -13.9  -17.9  -19.9  -19.9 </span></span><br><span class="line"><span class="string"> -19.9  -19.9  -17.9  -13.9 </span></span><br><span class="line"><span class="string"> -21.9  -19.9  -13.9    0.0 </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p><strong>贪婪策略</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">V = [<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">16</span>)]  <span class="comment"># 初始化价值</span></span><br><span class="line">V_eva = policy_evaluate(MDP, V, greedy_pi, <span class="number">100</span>)</span><br><span class="line">display_V(V_eva)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; 策略评估 贪婪策略</span></span><br><span class="line"><span class="string"># 迭代1轮的结果</span></span><br><span class="line"><span class="string">   0.0   -1.0   -1.0   -1.0 </span></span><br><span class="line"><span class="string">  -1.0   -1.0   -1.0   -1.0 </span></span><br><span class="line"><span class="string">  -1.0   -1.0   -1.0   -1.0 </span></span><br><span class="line"><span class="string">  -1.0   -1.0   -1.0    0.0 </span></span><br><span class="line"><span class="string"># 迭代2轮的结果</span></span><br><span class="line"><span class="string">   0.0   -1.0   -2.0   -2.0 </span></span><br><span class="line"><span class="string">  -1.0   -2.0   -2.0   -2.0 </span></span><br><span class="line"><span class="string">  -2.0   -2.0   -2.0   -1.0 </span></span><br><span class="line"><span class="string">  -2.0   -2.0   -1.0    0.0 </span></span><br><span class="line"><span class="string"># 迭代3轮的结果</span></span><br><span class="line"><span class="string">   0.0   -1.0   -2.0   -3.0 </span></span><br><span class="line"><span class="string">  -1.0   -2.0   -3.0   -2.0 </span></span><br><span class="line"><span class="string">  -2.0   -3.0   -2.0   -1.0 </span></span><br><span class="line"><span class="string">  -3.0   -2.0   -1.0    0.0 </span></span><br><span class="line"><span class="string"># 迭代100轮的结果</span></span><br><span class="line"><span class="string">   0.0   -1.0   -2.0   -3.0 </span></span><br><span class="line"><span class="string">  -1.0   -2.0   -3.0   -2.0 </span></span><br><span class="line"><span class="string">  -2.0   -3.0   -2.0   -1.0 </span></span><br><span class="line"><span class="string">  -3.0   -2.0   -1.0    0.0 </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="策略迭代policy-iteration"><a class="markdownIt-Anchor" href="#策略迭代policy-iteration"></a> 策略迭代(Policy iteration)</h2>
<p>策略评估仅仅对给定策略进行了状态价值评估，显然，个体可以根据得到的价值状态来调整自己的行动策略。即给定一个策略<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">π</span></span></span></span>,可以得到基于该策略的价值函数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>v</mi><mi>π</mi></msub></mrow><annotation encoding="application/x-tex">v_\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>,基于产生的价值函数有可以得到一个贪婪策略<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>π</mi><mi mathvariant="normal">’</mi></msup><mo>=</mo><mi>g</mi><mi>r</mi><mi>e</mi><mi>e</mi><mi>d</mi><mi>y</mi><mo stretchy="false">(</mo><msub><mi>v</mi><mi>π</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi^’=greedy(v_\pi)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.849108em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">’</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault">e</span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，依据新的策略又可以得到新的价值函数，重复循环迭代最终得到最优价值函数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>v</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">v^*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.688696em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span>和最优策略<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>π</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">\pi^*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.688696em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span>，这就是策略迭代。</p>
<p>我们在小型方格世界中进行贪婪策略迭代，并<strong>每迭代1次改善1次策略，共进行100次策略改善</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">policy_iterate</span>(<span class="params">MDP, V, Pi, n, m</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        V = policy_evaluate(MDP, V, Pi, n)</span><br><span class="line">        Pi = greedy_pi</span><br><span class="line">    <span class="keyword">return</span> V</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">V = [<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">16</span>)]  <span class="comment"># 初始化价值</span></span><br><span class="line">V_eva = policy_iterate(MDP, V, greedy_pi, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">display_V(V_eva)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"># 策略迭代 迭代1次改善100次策略</span></span><br><span class="line"><span class="string">   0.0   -1.0   -2.0   -3.0 </span></span><br><span class="line"><span class="string">  -1.0   -2.0   -3.0   -2.0 </span></span><br><span class="line"><span class="string">  -2.0   -3.0   -2.0   -1.0 </span></span><br><span class="line"><span class="string">  -3.0   -2.0   -1.0    0.0 </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>这里可以看出实际上和贪婪策略是一样的最终，因为我们在迭代优化的时候没有对策略进行评估，只是一昧的进行迭代，很可能在很早的迭代次数就已经达到了收敛。</p>
<h2 id="价值迭代value-iteration"><a class="markdownIt-Anchor" href="#价值迭代value-iteration"></a> 价值迭代(Value iteration)</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_v_from_max_q</span>(<span class="params">MDP, V, s</span>):</span></span><br><span class="line">    S, A, R, P, gamma = MDP</span><br><span class="line">    v_s = -<span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> A:</span><br><span class="line">        qs = compute_q(MDP, V, s, a)</span><br><span class="line">        <span class="keyword">if</span> qs &gt;= v_s:</span><br><span class="line">            v_s = qs</span><br><span class="line">    <span class="keyword">return</span> v_s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_V_without_pi</span>(<span class="params">MDP, V</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    无策略，仅依靠状态价值来更新状态价值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    S, _, _, _, _ = MDP</span><br><span class="line">    V_p = V.copy()</span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> S:</span><br><span class="line">        compu_v = compute_v_from_max_q(MDP, V_p, s)  <span class="comment"># 通过max q更新v</span></span><br><span class="line">        set_value(V_p, s, compu_v)</span><br><span class="line">    <span class="keyword">return</span> V_p</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">value_iterate</span>(<span class="params">MDP, V, n</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        V = update_V_without_pi(MDP, V)</span><br><span class="line">    <span class="keyword">return</span> V</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">V = [<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">16</span>)]  <span class="comment"># 初始化价值</span></span><br><span class="line">v_s = value_iterate(MDP, V, <span class="number">4</span>)</span><br><span class="line">display_V(v_s)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># 迭代4次后结果</span></span><br><span class="line"><span class="string">   0.0   -1.0   -2.0   -3.0 </span></span><br><span class="line"><span class="string">  -1.0   -2.0   -3.0   -2.0 </span></span><br><span class="line"><span class="string">  -2.0   -3.0   -2.0   -1.0 </span></span><br><span class="line"><span class="string">  -3.0   -2.0   -1.0    0.0 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Xiguapi</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://yuanyf.ml/2020/11/10/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92MDP/">http://yuanyf.ml/2020/11/10/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92MDP/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://yuanyf.ml" target="_blank">Xiguapi's Page</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/MDP/">MDP</a><a class="post-meta__tags" href="/tags/dynamic-programming/">dynamic programming</a><a class="post-meta__tags" href="/tags/Bellman-equation/">Bellman equation</a></div><div class="post_share"><div class="social-share" data-image="https://images.pexels.com/photos/261719/pexels-photo-261719.jpeg?cs=srgb&amp;dl=pexels-pixabay-261719.jpg&amp;fm=jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-full"><a href="/2020/11/24/%E5%B0%8F%E5%9E%8B%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"><img class="prev-cover" src="https://i.loli.net/2020/11/24/QtHpBnCxdoPTXJI.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">小型搜索引擎Novel Sou Sou</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2020/11/28/不基于模型的控制/" title="不基于模型的控制方法"><img class="cover" src="https://images.pexels.com/photos/261719/pexels-photo-261719.jpeg?cs=srgb&dl=pexels-pixabay-261719.jpg&fm=jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-11-28</div><div class="title">不基于模型的控制方法</div></div></a></div><div><a href="/2020/11/26/不基于模型的预测/" title="不基于模型的预测方法"><img class="cover" src="https://images.pexels.com/photos/261719/pexels-photo-261719.jpeg?cs=srgb&dl=pexels-pixabay-261719.jpg&fm=jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-11-26</div><div class="title">不基于模型的预测方法</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="lv-container" data-id="city" data-uid="MTAyMC81MjMwOS8yODc4Nw"></div></div></div></div></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/a1.gif" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Xiguapi</div><div class="author-info__description">no fear of words, no fear of years.</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">34</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/pickxiguapi"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/pickxiguapi" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:yuanyf1999@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://qm.qq.com/cgi-bin/qm/qr?k=ioUJlpU-XAiqna8X8yWUgTxMVxykkhZ8&amp;noverify=0" target="_blank" title="QQ"><i class="fab fa-qq"></i></a></div></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">Be positive, be patient.</div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="card-content"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%B1%82%E8%A7%A3%E5%B0%8F%E5%9E%8B%E6%96%B9%E6%A0%BC%E4%B8%96%E7%95%8C%E6%9C%80%E4%BC%98%E7%AD%96%E7%95%A5"><span class="toc-number">1.</span> <span class="toc-text"> 动态规划求解小型方格世界最优策略</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%9D%E6%83%B3"><span class="toc-number">1.1.</span> <span class="toc-text"> 动态规划思想</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#44%E5%B0%8F%E5%9E%8B%E6%96%B9%E6%A0%BC%E4%B8%96%E7%95%8Cmdp%E5%BB%BA%E6%A8%A1"><span class="toc-number">1.2.</span> <span class="toc-text"> 4*4小型方格世界MDP建模</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AD%96%E7%95%A5%E8%AF%84%E4%BC%B0policy-evalution"><span class="toc-number">1.3.</span> <span class="toc-text"> 策略评估(Policy evalution)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AD%96%E7%95%A5%E8%BF%AD%E4%BB%A3policy-iteration"><span class="toc-number">1.4.</span> <span class="toc-text"> 策略迭代(Policy iteration)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%B7%E5%80%BC%E8%BF%AD%E4%BB%A3value-iteration"><span class="toc-number">1.5.</span> <span class="toc-text"> 价值迭代(Value iteration)</span></a></li></ol></li></ol></div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/03/18/(GAT)GRAPH%20ATTENTION%20NETWORKS/" title="GNN 4: GRAPH ATTENTION NETWORKS（GAT论文阅读笔记及相关理解）"><img src="https://i.loli.net/2021/03/19/2BlMqDRP98wdigk.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="GNN 4: GRAPH ATTENTION NETWORKS（GAT论文阅读笔记及相关理解）"/></a><div class="content"><a class="title" href="/2021/03/18/(GAT)GRAPH%20ATTENTION%20NETWORKS/" title="GNN 4: GRAPH ATTENTION NETWORKS（GAT论文阅读笔记及相关理解）">GNN 4: GRAPH ATTENTION NETWORKS（GAT论文阅读笔记及相关理解）</a><time datetime="2021-03-18T09:20:17.000Z" title="发表于 2021-03-18 17:20:17">2021-03-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/03/12/(GASIL)predator-prey%E6%94%B9%E8%BF%9B%E7%89%88%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83/" title="GASIL cooperative predator-prey实验环境分析"><img src="https://raw.githubusercontent.com/tjuHaoXiaotian/GASIL/master/files/img/predator-prey.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="GASIL cooperative predator-prey实验环境分析"/></a><div class="content"><a class="title" href="/2021/03/12/(GASIL)predator-prey%E6%94%B9%E8%BF%9B%E7%89%88%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83/" title="GASIL cooperative predator-prey实验环境分析">GASIL cooperative predator-prey实验环境分析</a><time datetime="2021-03-12T02:45:54.000Z" title="发表于 2021-03-12 10:45:54">2021-03-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/03/07/(DPIQN)A%20Deep%20Policy%20Inference%20Q-Network%20for%20Multi-Agent%20Systems/" title="Opponent Modeling 3： A Deep Policy Inference Q-Network for Multi-Agent Systems（论文阅读笔记）"><img src="https://i.loli.net/2021/03/10/doKT2WQphrujS5v.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Opponent Modeling 3： A Deep Policy Inference Q-Network for Multi-Agent Systems（论文阅读笔记）"/></a><div class="content"><a class="title" href="/2021/03/07/(DPIQN)A%20Deep%20Policy%20Inference%20Q-Network%20for%20Multi-Agent%20Systems/" title="Opponent Modeling 3： A Deep Policy Inference Q-Network for Multi-Agent Systems（论文阅读笔记）">Opponent Modeling 3： A Deep Policy Inference Q-Network for Multi-Agent Systems（论文阅读笔记）</a><time datetime="2021-03-07T13:12:02.000Z" title="发表于 2021-03-07 21:12:02">2021-03-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/02/08/(DeepBPR+)A%20Deep%20Bayesian%20Policy%20Reuse%20Approach%20Against%20Non-Stationary%20Agent/" title="Opponent Modeling 2： A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents（Deep BPR+论文阅读笔记）"><img src="https://i.loli.net/2021/02/27/PNrS8emZquV2sAJ.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Opponent Modeling 2： A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents（Deep BPR+论文阅读笔记）"/></a><div class="content"><a class="title" href="/2021/02/08/(DeepBPR+)A%20Deep%20Bayesian%20Policy%20Reuse%20Approach%20Against%20Non-Stationary%20Agent/" title="Opponent Modeling 2： A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents（Deep BPR+论文阅读笔记）">Opponent Modeling 2： A Deep Bayesian Policy Reuse Approach Against Non-Stationary Agents（Deep BPR+论文阅读笔记）</a><time datetime="2021-02-08T07:51:11.000Z" title="发表于 2021-02-08 15:51:11">2021-02-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/01/29/(DGN)GRAPH%20CONVOLUTIONAL%20REINFORCEMENT%20LEARNING/" title="GNN 2: GRAPH CONVOLUTIONAL REINFORCEMENT LEARNING（论文阅读笔记）"><img src="https://i.loli.net/2021/02/04/gHlpVbZ5n3AWeyQ.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="GNN 2: GRAPH CONVOLUTIONAL REINFORCEMENT LEARNING（论文阅读笔记）"/></a><div class="content"><a class="title" href="/2021/01/29/(DGN)GRAPH%20CONVOLUTIONAL%20REINFORCEMENT%20LEARNING/" title="GNN 2: GRAPH CONVOLUTIONAL REINFORCEMENT LEARNING（论文阅读笔记）">GNN 2: GRAPH CONVOLUTIONAL REINFORCEMENT LEARNING（论文阅读笔记）</a><time datetime="2021-01-29T01:39:25.000Z" title="发表于 2021-01-29 09:39:25">2021-01-29</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Xiguapi</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> {preloader.endLoading()})</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>$(function () {
  $('span.katex-display').wrap('<div class="katex-wrap"></div>')
})</script><script>function loadLivere () {
  if (typeof LivereTower === 'object') {
    window.LivereTower.init()
  }
  else {
    (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
    })(document, 'script');
  }
}

if ('Livere' === 'Livere' || !false) {
  if (false) btf.loadComment(document.getElementById('lv-container'), loadLivere)
  else loadLivere()
}
else {
  function loadOtherComment () {
    loadLivere()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script></div></body></html>